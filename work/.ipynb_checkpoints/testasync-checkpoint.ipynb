{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4420c756-9533-4e93-9486-cabc314efba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### TEST\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time\n",
    "import pytz\n",
    "from datetime import timedelta\n",
    "\n",
    "import nest_asyncio\n",
    "import asyncio\n",
    "import aiohttp\n",
    "from prefect import flow, task # Prefect flow and task decorators\n",
    "from math import ceil\n",
    "\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "\n",
    "@task\n",
    "async def fetch_pollution_data(coord_df, batch_size=50):\n",
    "    API_KEY = \"68c16da5e675ad8635df84629765b118\"\n",
    "    # WEATHER_ENDPOINT = \"https://api.openweathermap.org/data/2.5/weather\"\n",
    "    POLLUTION_ENDPOINT = \"http://api.openweathermap.org/data/2.5/air_pollution\"\n",
    "    \n",
    "    async def fetch_row(session, row):\n",
    "        # await asyncio.sleep(1)  # ‚úÖ ‡∏û‡∏±‡∏Å 1 ‡∏ß‡∏¥‡πÅ‡∏ö‡∏ö‡πÑ‡∏°‡πà‡∏ö‡∏•‡πá‡∏≠‡∏Å loop\n",
    "        lat = row['lat']\n",
    "        lon = row['lon']\n",
    "        province = row['province']\n",
    "        amphoe = row['amphoe']\n",
    "        try:\n",
    "            params = {\n",
    "                \"lat\" : lat,\n",
    "                \"lon\" : lon,\n",
    "                \"appid\": API_KEY,\n",
    "                \"units\": \"metric\"\n",
    "            }\n",
    "            async with session.get(POLLUTION_ENDPOINT, params=params) as response:\n",
    "                if response.status != 200:\n",
    "                    return {\n",
    "                        'province': province,\n",
    "                        'amphoe': amphoe,\n",
    "                        'lat': lat,\n",
    "                        'lon': lon,\n",
    "                        'error': f\"HTTP {response.status}\"\n",
    "                    }\n",
    "                    data = await response.json()\n",
    "                    dt = datetime.utcnow()\n",
    "                    thai_tz = pytz.timezone('Asia/Bangkok')\n",
    "                    localtime = dt.astimezone(thai_tz)\n",
    "                    components = data['list'][0]['components']\n",
    "                    pollution_dict = {\n",
    "                        'timestamp': dt,\n",
    "                        'year': dt.year,\n",
    "                        'month': dt.month,\n",
    "                        'day': dt.day,\n",
    "                        'hour': dt.hour,\n",
    "                        'minute': dt.minute,\n",
    "                        'localtime': localtime,\n",
    "                        'province' : province,\n",
    "                        'amphoe' : amphoe,\n",
    "                        'lat' : data['coord']['lat'],\n",
    "                        'lon' : data['coord']['lon'],\n",
    "                        # 'location': data['name'],\n",
    "                        'aqi' : data['list'][0]['main']['aqi'],\n",
    "                        'co' : components['co'],\n",
    "                        'no' : components['no'],\n",
    "                        'no2' : components['no2'],\n",
    "                        'o3' : components['o3'],\n",
    "                        'so2' : components['so2'],\n",
    "                        'pm25' : components['pm2_5'],\n",
    "                        'pm10' : components['pm10'],\n",
    "                        'nh3' : components['nh3']\n",
    "                    }\n",
    "                    return pollution_dict\n",
    "\n",
    "        except Exception as e:\n",
    "            return {\n",
    "                'province': row.get('province', 'unknown'),\n",
    "                'amphoe': row.get('amphoe', 'unknown'),\n",
    "                'lat': row.get('lat', None),\n",
    "                'lon': row.get('lon', None),\n",
    "                'error': str(e)\n",
    "        }\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Error fetching data: {e}\")\n",
    "            return None\n",
    "        except KeyError as e:\n",
    "            print(f\"Error processing data: Missing key {e}\")\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e} at {province} - {amphoe}\")\n",
    "            return None\n",
    "\n",
    "\n",
    "\n",
    "    pollution_results = []\n",
    "    total_batches = ceil(len(coord_df) / batch_size)\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        for i in range(total_batches):\n",
    "            batch = coord_df.iloc[i*batch_size:(i+1)*batch_size]\n",
    "            tasks = [fetch_row(session, row) for _, row in batch.iterrows()]\n",
    "            batch_results = await asyncio.gather(*tasks)\n",
    "            pollution_results.extend(batch_results)\n",
    "\n",
    "            print(f\"‚úÖ ‡πÄ‡∏™‡∏£‡πá‡∏à batch {i+1}/{total_batches}\")\n",
    "            if i < total_batches - 1:\n",
    "                await asyncio.sleep(65)  # ‚úÖ ‡∏£‡∏≠‡πÉ‡∏´‡πâ‡∏ú‡πà‡∏≤‡∏ô rate limit\n",
    "                \n",
    "    return pollution_results\n",
    "            \n",
    "\n",
    "        # Make API request\n",
    "        # response = requests.get(POLLUTION_ENDPOINT, params=params)\n",
    "        # response.raise_for_status()  # Raise an exception for bad status codes\n",
    "        # data = response.json()\n",
    "        # return data\n",
    "\n",
    "# get_pollution_data()\n",
    "\n",
    "# import time\n",
    "\n",
    "# @flow(name=\"pollution-flow\")\n",
    "# async def pollution_flow():\n",
    "#     start_time = time.perf_counter()  # ‚è± ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏à‡∏±‡∏ö‡πÄ‡∏ß‡∏•‡∏≤\n",
    "\n",
    "#     coord_df = pd.read_csv('./save/amphoe_coord.csv')\n",
    "#     results = await fetch_pollution_data(coord_df)\n",
    "#     pollution_data = pd.DataFrame(results)\n",
    "\n",
    "#     end_time = time.perf_counter()  # ‚è± ‡∏à‡∏±‡∏ö‡πÄ‡∏ß‡∏•‡∏≤‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á\n",
    "#     elapsed = end_time - start_time\n",
    "#     print(f\"\\n‚úÖ ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏™‡∏£‡πá‡∏à‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î ‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏•‡∏≤ {elapsed:.2f} ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ\")\n",
    "#     return pollution_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f1ca1ec-84f3-4fe5-94d8-d44e4a3742f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "@flow(name=\"pollution-flow\")\n",
    "async def pollution_flow():\n",
    "    start_time = time.perf_counter()  # ‚è± ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏à‡∏±‡∏ö‡πÄ‡∏ß‡∏•‡∏≤\n",
    "    \n",
    "    coord_df = pd.read_csv('./save/amphoe_coord.csv')\n",
    "    pollution_results = await fetch_pollution_data(coord_df)\n",
    "    pollution_data = pd.DataFrame(pollution_results)\n",
    "\n",
    "    end_time = time.perf_counter()  # ‚è± ‡∏à‡∏±‡∏ö‡πÄ‡∏ß‡∏•‡∏≤‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á\n",
    "    print(f\"\\n‚úÖ ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏™‡∏£‡πá‡∏à‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î ‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏•‡∏≤ {end_time - start_time:.2f} ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ\")\n",
    "    return pollution_data\n",
    "\n",
    "\n",
    "# @flow(name=\"pollution-flow\")\n",
    "# async def pollution_flow():\n",
    "#     start_time = time.perf_counter()\n",
    "#     coord_df = pd.read_csv('./save/amphoe_coord.csv')\n",
    "#     pollution_results = await fetch_pollution_data(coord_df)\n",
    "    \n",
    "#     # üëâ filter error ‡∏≠‡∏≠‡∏Å‡∏Å‡πà‡∏≠‡∏ô‡πÄ‡∏Å‡πá‡∏ö\n",
    "#     pollution_data = pd.DataFrame(pollution_results)\n",
    "#     clean_data = pollution_data[pollution_data['error'].isna()].drop(columns=[\"error\"], errors=\"ignore\")\n",
    "\n",
    "#     end_time = time.perf_counter()\n",
    "#     print(f\"\\n‚úÖ ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏™‡∏£‡πá‡∏à‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î ‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏•‡∏≤ {end_time - start_time:.2f} ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ\")\n",
    "#     return clean_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "40ba3c66-7892-4f35-996a-1c78e52f98ef",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pollution_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mpollution_data\u001b[49m\n",
      "\u001b[31mNameError\u001b[39m: name 'pollution_data' is not defined"
     ]
    }
   ],
   "source": [
    "pollution_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22bfb187-4f93-49a1-924d-04238cb67c95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5394fee3-d882-4108-bc94-3d285e991b38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">20:23:49.137 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | prefect.engine - Created flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'flawless-mantis'</span> for flow<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> 'pollution-flow'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "20:23:49.137 | \u001b[36mINFO\u001b[0m    | prefect.engine - Created flow run\u001b[35m 'flawless-mantis'\u001b[0m for flow\u001b[1;35m 'pollution-flow'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">20:23:49.142 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | prefect.engine - View at <span style=\"color: #0000ff; text-decoration-color: #0000ff\">http://prefect-server:4200/runs/flow-run/1a075588-f21c-4e1e-af58-628bcc521e34</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "20:23:49.142 | \u001b[36mINFO\u001b[0m    | prefect.engine - View at \u001b[94mhttp://prefect-server:4200/runs/flow-run/1a075588-f21c-4e1e-af58-628bcc521e34\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">20:23:49.402 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'fetch_pollution_data-0' - Created task run 'fetch_pollution_data-0' for task 'fetch_pollution_data'\n",
       "</pre>\n"
      ],
      "text/plain": [
       "20:23:49.402 | \u001b[36mINFO\u001b[0m    | Task run 'fetch_pollution_data-0' - Created task run 'fetch_pollution_data-0' for task 'fetch_pollution_data'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ‡πÄ‡∏™‡∏£‡πá‡∏à batch 1/19\n"
     ]
    }
   ],
   "source": [
    "# test-run pollution flow\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "await pollution_flow()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b96a0c1-a217-4082-aa1b-605ac1ccb83b",
   "metadata": {},
   "outputs": [],
   "source": [
    " # lakeFS credentials from your docker-compose.yml\n",
    "ACCESS_KEY = \"access_key\"\n",
    "SECRET_KEY = \"secret_key\"\n",
    "    \n",
    "# lakeFS endpoint (running locally)\n",
    "lakefs_endpoint = \"http://lakefs-dev:8000/\"\n",
    "    \n",
    "    # lakeFS repository, branch, and file path\n",
    "repo = \"pollution-data\"\n",
    "branch = \"main\"\n",
    "path = \"pollution.parquet\"\n",
    "    \n",
    "    # Construct the full lakeFS S3-compatible path\n",
    "lakefs_s3_path = f\"s3a://{repo}/{branch}/{path}\"\n",
    "    \n",
    "    # Configure storage_options for lakeFS (S3-compatible)\n",
    "storage_options = {\n",
    "    \"key\": ACCESS_KEY,\n",
    "    \"secret\": SECRET_KEY,\n",
    "    \"client_kwargs\": {\n",
    "        \"endpoint_url\": lakefs_endpoint\n",
    "    }\n",
    "    }\n",
    "pollution_df.to_parquet(\n",
    "    lakefs_s3_path,\n",
    "    storage_options=storage_options,\n",
    "    partition_cols=['year','month','day','hour'],\n",
    "        \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1f4e8f-82ae-40e2-bd99-6cd3e60ecbfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5641972f-8c2e-4f2b-90c0-204e04e58bc0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# ‡∏Å‡∏£‡∏≠‡∏á‡πÄ‡∏≠‡∏≤‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏°‡∏µ key 'error'\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m clean_results = [r \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m \u001b[43mresults\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33merror\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m r]\n\u001b[32m      3\u001b[39m pollution_data = pd.DataFrame(clean_results)\n",
      "\u001b[31mNameError\u001b[39m: name 'results' is not defined"
     ]
    }
   ],
   "source": [
    "# ‡∏Å‡∏£‡∏≠‡∏á‡πÄ‡∏≠‡∏≤‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏°‡∏µ key 'error'\n",
    "clean_results = [r for r in results if 'error' not in r]\n",
    "pollution_data = pd.DataFrame(clean_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb031cdb-885c-4d81-ae4c-4cf9ca311c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = [r for r in results if 'error' in r]\n",
    "pd.DataFrame(errors).to_csv(\"pollution_errors.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e81b2bd-a90f-4cbd-8ada-c8d31fb533ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = await fetch_pollution_data(coord_df)\n",
    "\n",
    "# ‡πÅ‡∏¢‡∏Å clean ‡∏Å‡∏±‡∏ö error ‡∏≠‡∏≠‡∏Å\n",
    "clean_results = [r for r in results if 'error' not in r]\n",
    "error_results = [r for r in results if 'error' in r]\n",
    "\n",
    "# ‡∏™‡∏£‡πâ‡∏≤‡∏á DataFrame\n",
    "clean_df = pd.DataFrame(clean_results)\n",
    "error_df = pd.DataFrame(error_results)\n",
    "\n",
    "# Save ‡πÑ‡∏ü‡∏•‡πå clean ‡∏Ç‡∏∂‡πâ‡∏ô LakeFS (‡∏´‡∏£‡∏∑‡∏≠ local ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏≠‡∏±‡∏õ)\n",
    "clean_df.to_parquet(\"pollution_data.parquet\", index=False)\n",
    "\n",
    "# ‡πÄ‡∏Å‡πá‡∏ö error ‡πÑ‡∏ß‡πâ‡∏î‡∏π‡∏†‡∏≤‡∏¢‡∏´‡∏•‡∏±‡∏á (optional)\n",
    "if not error_df.empty:\n",
    "    error_df.to_csv(\"pollution_errors.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff3f6f8-9fb4-4462-acc9-03eed52787c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prefect import flow, task\n",
    "\n",
    "@task\n",
    "async def fetch_pollution_data(...):\n",
    "    ...\n",
    "\n",
    "def clean_data(results):\n",
    "    df = pd.DataFrame(results)\n",
    "    df = df[df['error'].isna()]  # ‡∏Å‡∏£‡∏≠‡∏á error ‡∏≠‡∏≠‡∏Å\n",
    "    return df.drop(columns=['error'], errors='ignore')\n",
    "\n",
    "def save_to_lakefs(df, path):\n",
    "    df.to_parquet(path, index=False)\n",
    "\n",
    "@flow\n",
    "async def pollution_pipeline():\n",
    "    raw_results = await fetch_pollution_data(...)\n",
    "    clean_df = clean_data(raw_results)\n",
    "    save_to_lakefs(clean_df, \"s3://lakefs/bucket/pollution.parquet\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
